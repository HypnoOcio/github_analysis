{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook shows training process of the models."
      ],
      "metadata": {
        "id": "dOPJjAmdS0FN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbynRVRP_aOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17d0481-8789-4ca6-8da0-01a9af20f8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Bidirectional,Dropout, Dense, Concatenate, LSTM, BatchNormalization \n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Conv1D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.utils import Sequence,to_categorical\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "MVXIcKMLS5Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from training_utils.generator import DataGenerator\n",
        "from training_utils.utils import train_test_split_timeseries, create_checkpoint, show_stats, train_model\n",
        "\n",
        "from models.arch import rnn_architecture, cnn_architecture"
      ],
      "metadata": {
        "id": "IMkLvar1S_-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EdKnoj8WRvq",
        "outputId": "420c642f-2632-475b-a619-44a7114fde31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = './data/data_for_training.csv'\n",
        "df_all = pd.read_csv(path_to_file)"
      ],
      "metadata": {
        "id": "wqQFHPtHVxjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_valid = train_test_split_timeseries(df_all, 0.75)\n",
        "df_valid, df_test  = train_test_split_timeseries(df_valid, 0.6)"
      ],
      "metadata": {
        "id": "_2a1KH4BTLIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "least_months_repo_is_active = 24\n",
        "batch_size = 4\n",
        "num_classes = 2\n",
        "# number of timeseries per one data point\n",
        "num_timeseries = len( [col for col in df_train.columns if \"_count\" in col] )\n",
        "num_epochs = 40"
      ],
      "metadata": {
        "id": "KVFu47TpUzd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = DataGenerator(list_IDs = df_train.project_id.unique(),\n",
        "                                   data = df_train,\n",
        "                                   batch_size = batch_size, dim = (least_months_repo_is_active, num_timeseries),\n",
        "                                   n_classes = num_classes, shuffle = True, months_cnt = least_months_repo_is_active)\n",
        "\n",
        "valid_generator = DataGenerator(list_IDs = df_valid.project_id.unique(),\n",
        "                                   data = df_valid,\n",
        "                                   batch_size = batch_size, dim = (least_months_repo_is_active, num_timeseries),\n",
        "                                   n_classes = num_classes, shuffle = False, months_cnt = least_months_repo_is_active)\n",
        "\n",
        "test_generator  = DataGenerator(list_IDs = df_test.project_id.unique(),\n",
        "                                   data = df_test,\n",
        "                                   batch_size = batch_size, dim = (least_months_repo_is_active, num_timeseries),\n",
        "                                   n_classes = num_classes, shuffle = False, months_cnt = least_months_repo_is_active)\n",
        "\n",
        "x_shape, y_shape = train_generator[0][0].shape, train_generator[0][1].shape\n",
        "print(f'x shape: {x_shape}\\ny shape: {y_shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewqxRuQ4Wq5d",
        "outputId": "d3306b9f-ce4f-4c19-e5a3-7bb69c5f1058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: (4, 24, 3)\n",
            "y shape: (4, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define timesteps and the number of features\n",
        "n_timesteps = x_shape[1]\n",
        "n_features = x_shape[2]"
      ],
      "metadata": {
        "id": "bTyzHFzQWt7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train LSTM network\n",
        "\n",
        "model = rnn_architecture(num_classes = num_classes, n_timesteps = n_timesteps, n_features = n_features)\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\",])\n",
        "# model.summary()\n",
        "model_checkpoint = create_checkpoint(\"LSTM\")\n",
        "history = train_model(model ,train_generator, num_epochs, batch_size, valid_generator, model_checkpoint= None)\n"
      ],
      "metadata": {
        "id": "ThjcuIrOYHnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train CNN network\n",
        "\n",
        "model = cnn_architecture(num_classes = num_classes, n_timesteps = n_timesteps, n_features = n_features)\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\",])# focal loss\n",
        "# model.summary()\n",
        "model_checkpoint = create_checkpoint(\"CNN\")\n",
        "history = train_model(model ,train_generator, num_epochs, batch_size, valid_generator, model_checkpoint= None)"
      ],
      "metadata": {
        "id": "c5dQTp-4Ylvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test accuracy for CNN on test data.\n",
        "\n"
      ],
      "metadata": {
        "id": "IxrYZ3d4l5Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "path_to_weights = {'LSTM':'./model_weights/weights_LSTM.15-0.9049-0.7679.hdf5', 'CNN':'weights_CNN.13-0.5174-0.7857.hdf5'}\n",
        "\n",
        "model.load_weights(path_to_weights['CNN'])\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for X,y in test_generator:\n",
        "  x_test.append(X)\n",
        "  y_test.append(y)\n",
        "\n",
        "x_test = np.stack(x_test).reshape((-1,least_months_repo_is_active,num_timeseries))\n",
        "y_test = np.stack(y_test).reshape((-1,num_classes))\n",
        "y_test = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(f'y_pred: {y_pred}')\n",
        "print(f'y_test: {y_test}')\n",
        "\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"----------conf matrix----------\")\n",
        "print(conf_mat)\n",
        "print(f'test acc: {(conf_mat[0][0] + conf_mat[1][1])/conf_mat.sum()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un4gu46Umu3n",
        "outputId": "570d6342-978f-4256-b03d-8245e7174214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred: [1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0]\n",
            "y_test: [1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0]\n",
            "----------conf matrix----------\n",
            "[[14  5]\n",
            " [ 0 17]]\n",
            "test acc: 0.8611111111111112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hMIbZm3jnAng"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}